{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3541ce4",
   "metadata": {},
   "source": [
    "# Processing Data from Sensor.Community in Near-Real Time Setup (AD4GD, Pilot 3)\n",
    "\n",
    "This notebook demonstrates how to process near real-time air quality data from the SDS011 sensor on the Sensor.Community network. The workflow includes downloading raw data, standardizing the format, and applying corrections using meteorological and model data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acb5672",
   "metadata": {},
   "source": [
    "### Step 1: Setup and Imports\n",
    "We import the necessary Python modules and helper functions for downloading and processing the data. Make sure the *data_processing* module is in your Python path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9313ab28",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_processing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdata_processing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstandardize_sensor_community\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardizeData\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdata_processing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_data_nrt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (get_sensor_community_urls,\n\u001b[1;32m      6\u001b[0m                                                processs_sensor_community_nrt,\n\u001b[1;32m      7\u001b[0m                                                download_ecmwf_data)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdata_processing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miot_qa_hour\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Corrector\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data_processing'"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from data_processing.standardize_sensor_community import StandardizeData\n",
    "from data_processing.download_data_nrt import (get_sensor_community_urls,\n",
    "                                               process_sensor_community_nrt,\n",
    "                                               download_ecmwf_data)\n",
    "from data_processing.iot_qa_hour import Corrector\n",
    "from data_processing.kriging_only import KrigingIoT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40763874",
   "metadata": {},
   "source": [
    "### Step 2: Get Download URLs for NRT Data\n",
    "This step generates a list of URLs pointing to raw data for a specific sensor and date. This list is saved to a text file and can be used for bulk downloading. For fast downloading, rather use *aria2c* than *wget*\n",
    "> aria2c -x6 -i ./sensor_community_urls.txt -d ./L0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bd888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get urls for downloading (NRT) data from sensor.community\n",
    "date = datetime(2025, 5, 1)\n",
    "sensor = 'sds011'\n",
    "urlfn = Path('/scratch/ecm7934/ad4gd_pilot3_test2') / 'sensor_community_urls.txt'\n",
    "get_sensor_community_urls(date, urlfn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8603a3bf",
   "metadata": {},
   "source": [
    "### Step 3: Merge Raw CSVs into a Single Parquet File\n",
    "After downloading, all CSV files are merged into a single Parquet file for easier processing and consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee5d706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now read downloaded csv files and merge them to one single parquet file for\n",
    "# further processing\n",
    "process_sensor_community_nrt(sensor=sensor, date=date, iotpath=Path('./L0/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002d08c2",
   "metadata": {},
   "source": [
    "### Step 4: Standardize to Hourly Averages\n",
    "This step converts the raw sensor data into hourly-averaged format, which is essential for consistent comparison and later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7bcf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize temporally uneven SDS011 data to hourly data\n",
    "inputfn = Path('.', 'L1A', 'sds011', f\"{sensor}_{date:%Y%m%d}.parquet\")\n",
    "outputfold = Path('.', 'L2')\n",
    "Standard = StandardizeData(date, sensor, inputfn, outputfold)\n",
    "Standard.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43afc93",
   "metadata": {},
   "source": [
    "### Step 5: Apply Corrections and Outlier Filtering\n",
    "In this step (partially shown), the standardized data is corrected using a machine learning model that integrates meteorological data (e.g. ERA5) and applies outlier detection based on CAMS Europe air quality model data. To this end, download download meteorological data (e.g. ERA5, ECMWF-IFS) and air quality model data (e.g. from CAMS Europe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d03219a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Correct hourly SDS011 data using ML model with ERA5 data as input\n",
    "# and apply outlier detection using CAMS data. To this end, download\n",
    "# download meteorological data (e.g. ERA5, ECMWF-IFS) and air quality model data\n",
    "# (e.g. from CAMS Europe).\n",
    "meteofold = Path('.', 'meteo')\n",
    "if not meteofold.exists():\n",
    "    meteofold.mkdir(parents=True)\n",
    "download_ecmwf_data(date, meteofold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89850826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct standardized SDS011 data using ML together with meteorological and CAMS data\n",
    "scomfn = Path('.', 'L2', f'SDS011_PM2.5_hourly_{date:%Y%m%d}.nc')\n",
    "pollutant = 'pm25'\n",
    "meteofn = Path(meteofold, f'meteo_{date:%Y%m%d}.nc')\n",
    "camsfn = Path(meteofold, f'cams_{date:%Y%m%d}.nc')\n",
    "outputfolder = Path('.', 'L2B')\n",
    "corr_outfn = Path(outputfolder, 'pm25', f'iot_hour_corr_pm25_{date:%Y%m%d}.nc')\n",
    "\n",
    "Corr = Corrector(scomfn,\n",
    "                date,\n",
    "                pollutant,\n",
    "                meteofn,\n",
    "                camsfn,\n",
    "                outputfolder,\n",
    "                outfn=corr_outfn)\n",
    "Corr.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e95c9d",
   "metadata": {},
   "source": [
    "### Step 6: Regrid Corrected IoT Data Using Kriging\n",
    "In this final step, the corrected hourly IoT data is interpolated onto a regular latitude-longitude grid using a kriging algorithm. This spatial interpolation is crucial for integrating sensor data into structured gridded datasets, making it easier to:\n",
    "- Compare with satellite or model data,\n",
    "- Visualize on maps,\n",
    "- Integrate into further data processing workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd13952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-07 13:51:58.096567 Reading IoT data\n",
      "2025-07-07 13:52:23.309341 Processing 2024-12-01T00:00:00.000000000\n",
      "2025-07-07 13:52:23.317219 Identifying clusters\n",
      "2025-07-07 13:52:27.415335 Checking distance to nearest IoT station\n",
      "2025-07-07 13:52:27.415466 Create and query KDTree\n",
      "2025-07-07 13:52:39.716482 Calculate distances\n",
      "2025-07-07 13:52:39.873968 Performing global kriging\n"
     ]
    }
   ],
   "source": [
    "l3fold = Path('.', 'L3')\n",
    "if not l3fold.exists():\n",
    "    l3fold.mkdir(parents=True)\n",
    "\n",
    "outfn = Path(l3fold, f'iotonly_hour_pm25_gridded_{date:%Y%m%d}.nc')\n",
    "Kriging = KrigingIoT(timeliness='hourly',\n",
    "                     date=date,\n",
    "                     iotmeasfn=corr_outfn,\n",
    "                     outfn=outfn)\n",
    "Kriging.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
